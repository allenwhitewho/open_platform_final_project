import requests
from bs4 import BeautifulSoup
import time
import random

# ä½¿ç”¨ä¸€èˆ¬ sessionï¼Œä¸ç”¨ requests_cache
session = requests.Session()

# åŸºæœ¬ headers
headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)",
    "Referer": "https://www.books.com.tw/",
    "Accept-Language": "zh-TW,zh;q=0.9"
}
session.headers.update(headers)

# é˜²æ­¢è¢«å°æ©Ÿåˆ¶
def safe_sleep():
    t = random.uniform(3, 7)
    print(f"â³ ç­‰å¾… {t:.2f} ç§’...")
    time.sleep(t)

# åˆ†é¡æŠ“å–å‡½å¼
def get_category(book_url, retries=3):
    for attempt in range(retries):
        try:
            safe_sleep()
            res = session.get(book_url, timeout=15)
            res.raise_for_status()
            html = res.text

            if "é™åˆ¶ç´šå•†å“" in html or "18æ­²ä»¥ä¸Šæœƒå“¡" in html:
                return "é™åˆ¶ç´šå•†å“ï¼ˆéœ€ç™»å…¥ï¼‰"
            if "æ‚¨çš„é€£ç·šæš«æ™‚ç•°å¸¸" in html or "Connection is temporarily unavailable" in html:
                return "é€£ç·šæš«æ™‚ç•°å¸¸"

            soup = BeautifulSoup(html, "html.parser")
            breadcrumb = soup.select("ul#breadcrumb-trail li a")
            if len(breadcrumb) >= 3:
                return breadcrumb[2].text.strip()
            else:
                return "æœªçŸ¥åˆ†é¡"
        except Exception as e:
            time.sleep(60)
    return "åˆ†é¡è®€å–å¤±æ•—"
	
category_count = {}

# æŠ“æ’è¡Œæ¦œé 
url = "https://www.books.com.tw/web/sys_newtopb/books/"
res = session.get(url)
soup = BeautifulSoup(res.text, "html.parser")
books = soup.select("li.item")

# é–‹å§‹çˆ¬èŸ²
seen_links = set()
idx = 1
error_count = 0

import csv
import re
# å»ºç«‹ä¸€å€‹æ¸…å–®ä¾†å­˜æ¯æœ¬æ›¸çš„è³‡æ–™
book_data = []

# 23 - 73
for book in books[23:73]:
    title_tag = book.select_one("h4 > a")
    if not title_tag:
        continue

    original_link = title_tag["href"]
    book_id = original_link.split("/products/")[-1].split("?")[0]
    link = f"https://www.books.com.tw/products/{book_id}/{idx}"

    if link in seen_links:
        continue
    seen_links.add(link)

    title = title_tag.text.strip()
    author_tag = book.select_one("ul.msg li:nth-of-type(1) a")
    author = author_tag.text.strip() if author_tag else "æœªçŸ¥ä½œè€…"

    if author == "æœªçŸ¥ä½œè€…":
        # å¾è©³ç´°é æŠ“å‡ºç‰ˆç¤¾æ›¿ä»£ä½œè€…
        safe_sleep()
        try:
            detail_res = session.get(link, timeout=15)
            detail_res.raise_for_status()
            detail_soup = BeautifulSoup(detail_res.text, "html.parser")

            publisher = "æœªçŸ¥å‡ºç‰ˆç¤¾"
            meta_tag = detail_soup.select_one("meta[name=description]")
            if meta_tag and "å‡ºç‰ˆç¤¾ï¼š" in meta_tag["content"]:
                desc = meta_tag["content"]
                match = re.search(r"å‡ºç‰ˆç¤¾ï¼š(.+?)ï¼Œ", desc)
                if match:
                    publisher = match.group(1).strip()

            author = f"ï¼ˆå‡ºç‰ˆç¤¾ï¼š{publisher}ï¼‰"
        except Exception as e:
            print(f"âš ï¸ è©³ç´°é æŠ“å‡ºç‰ˆç¤¾å¤±æ•—ï¼š{e}")
            author = "æœªçŸ¥ä½œè€…"

    price_tag = book.select_one("ul.msg li.price_a")
    price = "æœªçŸ¥åƒ¹æ ¼"
    if price_tag:
        price_text = price_tag.get_text(strip=True)
        if "å…ƒ" in price_text:
            price = price_text.split("å…ƒ")[0].split("æŠ˜")[-1] + "å…ƒ"

    category = get_category(link)

    if category not in category_count:
        category_count[category] = 1
    else:
        category_count[category] += 1

    if "ç•°å¸¸" in category or "å¤±æ•—" in category:
        error_count += 1
    else:
        error_count = 0

    if error_count >= 1:
        print("âš ï¸ é€£çºŒå‡ºéŒ¯è¶…é 5 æ¬¡ï¼Œæš«åœ 60 ç§’...")
        time.sleep(60)
        error_count = 0
        category = get_category(link)

    print(f"{idx}. æ›¸å: {title}")
    print(f"    é€£çµ: {link}")
    print(f"    ä½œè€…: {author}")
    print(f"    åƒ¹æ ¼: {price}")
    print(f"    åˆ†é¡: {category}")
    idx += 1

    # æŠŠé€™ç­†è³‡æ–™åŠ å…¥ list
    book_data.append([title, author, price, category, link])

from datetime import datetime, timedelta
import pytz

# è¨­å®šæ™‚å€ç‚ºå°ç£
tz = pytz.timezone("Asia/Taipei")
now = datetime.now(tz).date()
'''+ timedelta(days=1)'''
now_str = now.strftime("%Y-%m-%d")

# å¯«å…¥ CSV æª”æ¡ˆï¼ˆæ¥çºŒå¯«å…¥ï¼‰
with open("static.csv", "w", newline="", encoding="utf-8-sig") as f:
    writer = csv.writer(f)
    
    # æ¯æ¬¡éƒ½å¯«å…¥æ™‚é–“åˆ—ï¼Œæ¨™ç¤ºè³‡æ–™æ‰¹æ¬¡é–‹å§‹
    writer.writerow([now_str])

    # å¯«å…¥æ¬„ä½æ¨™é¡Œ
    writer.writerow(["æ›¸å", "ä½œè€…", "åƒ¹æ ¼", "åˆ†é¡", "é€£çµ"])
    
    # å¯«å…¥è³‡æ–™
    writer.writerows(book_data)


print("\nğŸ“Š åˆ†é¡çµ±è¨ˆçµæœï¼ˆä¾å‡ºç¾æ¬¡æ•¸æ’åºï¼‰ï¼š")
for cat, count in sorted(category_count.items(), key=lambda x: x[1], reverse=True):
    print(f"åˆ†é¡ã€Œ{cat}ã€å‡ºç¾æ¬¡æ•¸ï¼š{count}")

# è®€å– history.csv èˆŠè³‡æ–™
import os

history_file = "history.csv"
sections = []  # æ¯å¤©ä¸€å€å¡Šï¼š[date_string, [rows...]]
if os.path.exists(history_file):
    with open(history_file, newline='', encoding='utf-8-sig') as f:
        reader = csv.reader(f)
        section = []
        section_date = None
        for row in reader:
            if not row:
                continue
            if len(row) == 1:
                try:
                    # å˜—è©¦è§£ææˆæ—¥æœŸï¼ˆç¢ºä¿çœŸçš„æ˜¯æ—¥æœŸæ ¼å¼ï¼‰
                    parsed_date = datetime.strptime(row[0], "%Y-%m-%d").date()
                    if section_date and section:
                        sections.append((section_date, section))
                    section_date = str(parsed_date)
                    section = []
                    continue
                except:
                    pass  # å¦‚æœä¸æ˜¯æ—¥æœŸå°±è·³éï¼Œç¹¼çºŒç´¯åŠ è³‡æ–™
            section.append(row)
        if section_date and section:
            sections.append((section_date, section))

# 3. æ–°å¢ä»Šå¤©çš„æ–°è³‡æ–™ï¼ˆæ ¼å¼åŒä¸Šï¼‰
new_section_rows = [["æ›¸å", "ä½œè€…", "åƒ¹æ ¼", "åˆ†é¡", "é€£çµ"]] + book_data
sections.append((str(now), new_section_rows))

# 4. ä¿ç•™æœ€æ–° 7 å¤©
# æ’åºä¸¦å»é‡ï¼ˆå¾Œé¢çš„æœƒè“‹æ‰å‰é¢çš„ï¼‰
latest = {}
for date_str, rows in sections:
    latest[date_str] = rows
# ä¿ç•™æœ€è¿‘ 7 å¤©
sorted_dates = sorted(latest.keys(), reverse=True)[:7]
sections = [(d, latest[d]) for d in sorted_dates]

# 5. å¯«å…¥ history.csv
with open(history_file, "w", newline='', encoding="utf-8-sig") as f:
    writer = csv.writer(f)
    for date_str, rows in reversed(sections):  # ç”±èˆŠåˆ°æ–°
        writer.writerow([date_str])
        writer.writerows(rows)

import pandas as pd

# æ­¥é©Ÿ 1ï¼šè®€å– history.csvï¼Œæ•´ç†æˆæ¯å¤©çš„ dataframe æ¸…å–®
history_file = "history.csv"
sections = []

with open(history_file, newline='', encoding="utf-8-sig") as f:
    reader = csv.reader(f)
    current_date = None
    current_rows = []

    for row in reader:
        if not row:
            continue
        if len(row) == 1 and row[0].count("-") == 2:  # åµæ¸¬æ—¥æœŸ
            if current_date and current_rows:
                df = pd.DataFrame(current_rows[1:], columns=current_rows[0])  # è·³éæ¬„ä½åˆ—
                sections.append((current_date, df))
            current_date = row[0].strip()
            current_rows = []
        else:
            current_rows.append(row)
    if current_date and current_rows:
        df = pd.DataFrame(current_rows[1:], columns=current_rows[0])
        sections.append((current_date, df))

# ä¿ç•™æœ€è¿‘ 7 å¤©
sections = sorted(sections, key=lambda x: x[0], reverse=True)[:7]
sections = list(reversed(sections))  # ç”±èˆŠåˆ°æ–°

# æ­¥é©Ÿ 2ï¼šå¯«å…¥ category_log.csvï¼ˆåˆ†é¡ Top å‡ºç¾æ¬¡æ•¸ï¼‰
header = ["æ™‚é–“"] + [f"Top{i}" for i in range(1, 21)]
csv_file = "category_log.csv"
with open(csv_file, "w", newline="", encoding="utf-8-sig") as f:
    writer = csv.writer(f)
    writer.writerow(header)
    for date_str, df in sections:
        category_count = df["åˆ†é¡"].value_counts().sort_values(ascending=False)
        row = [date_str] + [f"{cat}({count})" for cat, count in category_count.items()]
        while len(row) < 21:
            row.append("")
        writer.writerow(row)

print("âœ… å·²å¾ history.csv çµ±è¨ˆè¿‘ä¸ƒå¤©åˆ†é¡ï¼Œå¯«å…¥ category_log.csvï¼ˆç„¡é‡è¤‡ï¼‰")

csv_file = "category_log.csv"

try:
    with open(csv_file, newline='', encoding='utf-8-sig') as f:
        reader = csv.reader(f)
        rows = list(reader)

        if not rows:
            print("âŒ æª”æ¡ˆæ˜¯ç©ºçš„")
        else:
            print("ğŸ“‹ category_log.csv å…§å®¹å¦‚ä¸‹ï¼š\n")
            for row in rows:
                print(" ï½œ ".join(row))

except FileNotFoundError:
    print("âŒ æ‰¾ä¸åˆ°æª”æ¡ˆ category_log.csv")
except Exception as e:
    print("âŒ ç™¼ç”ŸéŒ¯èª¤ï¼š", e)

import matplotlib.pyplot as plt
plt.rcParams['font.family'] = 'Microsoft JhengHei'  # æ”¹æˆä½ é›»è…¦æœ‰çš„ä¸­æ–‡å­—é«”
plt.rcParams['axes.unicode_minus'] = False  # é¿å…è² è™Ÿé¡¯ç¤ºæˆæ–¹å¡Š

# çµ±è¨ˆåˆ†é¡æ•¸é‡
category_counts = df["åˆ†é¡"].value_counts()

# ç•«å‡ºé•·æ¢åœ–
plt.figure(figsize=(12, 6))
category_counts.plot(kind='bar')
plt.title("å„é¡åˆ¥æ›¸ç±æ•¸é‡ï¼ˆå¸‚å åœ–ï¼‰", fontsize=16)
plt.xlabel("åˆ†é¡", fontsize=12)
plt.ylabel("æ›¸ç±æ•¸é‡", fontsize=12)
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.savefig("images/category_distribution_bar.png")  # ç”¨ä¸åŒæª”åå„²å­˜
plt.show()
plt.close()


# â€”â€”â€”â€”â€”â€” 1. åƒ¹æ ¼æ¬„ä½æ–‡å­—è½‰æ•¸å€¼ â€”â€”â€”â€”â€”â€”
# å‡è¨­åƒ¹æ ¼æ ¼å¼åƒ "250å…ƒ"ã€"90å…ƒ"ã€"æœªçŸ¥åƒ¹æ ¼"ï¼Œå…ˆå»æ‰ã€Œå…ƒã€å†è½‰ intï¼Œä¸å¯è½‰å‰‡è¨­ NaN
def parse_price(x):
    try:
        return int(x.replace("å…ƒ", ""))
    except:
        return None

df["åƒ¹æ ¼_æ•¸å€¼"] = df["åƒ¹æ ¼"].apply(parse_price)
df = df.dropna(subset=["åƒ¹æ ¼_æ•¸å€¼"])  # å»æ‰ç„¡æ³•è½‰æˆæ•¸å­—çš„åˆ—

# â€”â€”â€”â€”â€”â€” 2. ç®±å‹åœ–ï¼šå„åˆ†é¡åƒ¹æ ¼åˆ†å¸ƒ â€”â€”â€”â€”â€”â€”
plt.rcParams["font.family"] = "Microsoft JhengHei"
plt.rcParams["axes.unicode_minus"] = False

# ä½¿ç”¨ boxplotï¼Œå„åˆ†é¡åƒ¹æ ¼åˆ†å¸ƒ
df.boxplot(column="åƒ¹æ ¼_æ•¸å€¼", by="åˆ†é¡", rot=45, grid=False, showfliers=False)
plt.title("å„åˆ†é¡æ›¸ç±åƒ¹æ ¼ç®±å‹åœ–", fontsize=16)
plt.suptitle("")  # ç§»é™¤ pandas è‡ªå¸¶çš„å‰¯æ¨™é¡Œ
plt.xlabel("åˆ†é¡", fontsize=12)
plt.ylabel("åƒ¹æ ¼ï¼ˆå…ƒï¼‰", fontsize=12)
plt.tight_layout()
plt.savefig("images/category_price_boxplot.png")  # ç”¨ä¸åŒæª”åå„²å­˜
plt.show()
plt.close()

import seaborn as sns

plt.figure(figsize=(14, 6))
sns.stripplot(x="åˆ†é¡", y="åƒ¹æ ¼_æ•¸å€¼", data=df, jitter=True)
plt.xticks(rotation=45)
plt.title("å„åˆ†é¡æ›¸ç±åƒ¹æ ¼æ•£ä½ˆåœ–")
plt.xlabel("åˆ†é¡")
plt.ylabel("åƒ¹æ ¼ï¼ˆå…ƒï¼‰")
plt.tight_layout()
plt.savefig("images/category_price_scatter.png")  # ç”¨ä¸åŒæª”åå„²å­˜
plt.show()
plt.close()


history_file = "history.csv"
date = None
records = []

with open(history_file, encoding="utf-8-sig") as f:
    for line in f:
        line = line.strip()
        if not line:
            continue
        if len(line.split(",")) == 1 and line.count("-") == 2:
            date = line
        elif date and not line.startswith("æ›¸å"):
            parts = line.split(",")
            if len(parts) == 5:
                _, _, _, category, _ = parts
                records.append((date, category))

df_records = pd.DataFrame(records, columns=["æ—¥æœŸ", "åˆ†é¡"])
df_count = df_records.groupby(["æ—¥æœŸ", "åˆ†é¡"]).size().reset_index(name="æ›¸é‡")

# åšæˆ pivot table â†’ è¡Œï¼šåˆ†é¡ï¼›åˆ—ï¼šæ—¥æœŸï¼›å€¼ï¼šæ›¸é‡
df_pivot = df_count.pivot(index="åˆ†é¡", columns="æ—¥æœŸ", values="æ›¸é‡").fillna(0).astype(int)

df_pivot.T.plot(marker="o")
plt.title("å„åˆ†é¡å¸‚å è®ŠåŒ–æŠ˜ç·šåœ–ï¼ˆ7å¤©ï¼‰", fontsize=14)
plt.xlabel("æ—¥æœŸ")
plt.ylabel("æ›¸ç±æ•¸é‡")
plt.legend(title="åˆ†é¡", bbox_to_anchor=(1.05, 1), loc="upper left")
plt.tight_layout()
plt.savefig("images/category_trend_line.png")  # ç”¨ä¸åŒæª”åå„²å­˜
plt.show()
plt.close()

top_records = []
with open("category_log.csv", encoding="utf-8-sig") as f:
    for line in f:
        parts = line.strip().split(",")
        if len(parts) < 2: continue
        date = parts[0]
        for item in parts[1:]:
            if "(" in item and ")" in item:
                cat = item.split("(")[0]
                count = int(item.split("(")[1].replace(")", ""))
                top_records.append((date, cat, count))

df_top = pd.DataFrame(top_records, columns=["æ—¥æœŸ", "åˆ†é¡", "æ¬¡æ•¸"])
df_top_pivot = df_top.pivot(index="æ—¥æœŸ", columns="åˆ†é¡", values="æ¬¡æ•¸").fillna(0).astype(int)

df_top_pivot.plot(kind="bar", stacked=True)

plt.title("Top åˆ†é¡æ¯æ—¥é€²æ¦œæ¬¡æ•¸å †ç–Šåœ–", fontsize=14)
plt.xlabel("æ—¥æœŸ")
plt.ylabel("åˆ†é¡é€²æ¦œæ¬¡æ•¸")
plt.legend(title="åˆ†é¡", bbox_to_anchor=(1.05, 1), loc="upper left")
plt.tight_layout()
plt.savefig("images/category_top10_stacked.png")  # ç”¨ä¸åŒæª”åå„²å­˜
plt.show()
plt.close()

from collections import Counter
from matplotlib.ticker import MaxNLocator

# Step 1: è®€å…¥ history.csv
history_file = "history.csv"
top10_books = []

with open(history_file, encoding="utf-8-sig") as f:
    current_date = None
    current_books = []
    for line in f:
        line = line.strip()
        if not line:
            continue
        if "," not in line:
            # é‡åˆ°ã€Œåªæœ‰æ—¥æœŸã€çš„è¡Œï¼Œå°±æŠŠå‰ä¸€å¤©çš„å‰10æœ¬åŠ é€² list
            if current_date and current_books:
                top10_books += current_books[:10]
            current_date = line.strip()
            current_books = []
        else:
            parts = line.split(",")
            title = parts[0]
            if title != "æ›¸å":  # æ’é™¤è¡¨é ­
                current_books.append(title)


    # æœ€å¾Œä¸€å€‹æ—¥æœŸçš„æ›¸ä¹Ÿè¦åŠ 
    if current_date and current_books:
        top10_books += current_books[:10]

# Step 2: çµ±è¨ˆæ›¸åå‡ºç¾æ¬¡æ•¸
counter = Counter(top10_books)

# éæ¿¾å‡ºã€Œå‡ºç¾æ¬¡æ•¸ â‰¥ 2 æ¬¡ã€çš„æ›¸
filtered_common = [(t, c) for t, c in counter.most_common() if c >= 2]

# å¦‚æœæ²’æœ‰ä»»ä½•æ›¸å‡ºç¾æ¬¡æ•¸ â‰¥ 2ï¼Œæç¤ºä½¿ç”¨è€…
if not filtered_common:
    print("â—ç›®å‰æ²’æœ‰ä»»ä½•æ›¸åœ¨ 7 å¤©å…§å‡ºç¾è¶…éä¸€æ¬¡ï¼Œç„¡æ³•ç•«å‡ºå¸¸é§æ’è¡Œæ¦œã€‚")
else:
    # å–å‰ 10 åï¼ˆå¦‚æœå¤§æ–¼ 10ï¼‰
    top_common = filtered_common[:10]

    # Step 3: ç¹ªåœ–
    titles = [item[0] for item in top_common]
    counts = [item[1] for item in top_common]

    plt.figure(figsize=(12, 6))
    plt.barh(titles[::-1], counts[::-1])
    plt.title("Top å¸¸é§æ›¸åæ’è¡Œæ¦œï¼ˆå‡ºç¾æ¬¡æ•¸å¤§æ–¼2ï¼‰")
    plt.xlabel("å‡ºç¾æ¬¡æ•¸")
    plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))
    plt.tight_layout()
    plt.savefig("images/title_top10_bar.png")
    plt.show()
    plt.close()