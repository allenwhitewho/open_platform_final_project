import requests
from bs4 import BeautifulSoup
import time
import random

# ä½¿ç”¨ä¸€èˆ¬ sessionï¼Œä¸ç”¨ requests_cache
session = requests.Session()

# åŸºæœ¬ headers
headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)",
    "Referer": "https://www.books.com.tw/",
    "Accept-Language": "zh-TW,zh;q=0.9"
}
session.headers.update(headers)

# é˜²æ­¢è¢«å°æ©Ÿåˆ¶
def safe_sleep():
    t = random.uniform(3, 7)
    print(f"â³ ç­‰å¾… {t:.2f} ç§’...")
    time.sleep(t)

# åˆ†é¡æŠ“å–å‡½å¼
def get_category(book_url, retries=3):
    for attempt in range(retries):
        try:
            safe_sleep()
            res = session.get(book_url, timeout=15)
            res.raise_for_status()
            html = res.text

            if "é™åˆ¶ç´šå•†å“" in html or "18æ­²ä»¥ä¸Šæœƒå“¡" in html:
                return "é™åˆ¶ç´šå•†å“ï¼ˆéœ€ç™»å…¥ï¼‰"
            if "æ‚¨çš„é€£ç·šæš«æ™‚ç•°å¸¸" in html or "Connection is temporarily unavailable" in html:
                return "é€£ç·šæš«æ™‚ç•°å¸¸"

            soup = BeautifulSoup(html, "html.parser")
            breadcrumb = soup.select("ul#breadcrumb-trail li a")
            if len(breadcrumb) >= 3:
                return breadcrumb[2].text.strip()
            else:
                return "æœªçŸ¥åˆ†é¡"
        except Exception as e:
            time.sleep(60)
    return "åˆ†é¡è®€å–å¤±æ•—"

# å…ˆæ¸¬è©¦å€‹åˆ¥é€£çµæ˜¯å¦åˆ†é¡æ­£ç¢º
print(get_category("https://www.books.com.tw/products/0011016503?loc=P_0001_015"))
print(get_category("https://www.books.com.tw/products/0011015621?loc=P_0001_016"))

category_count = {}

# æŠ“æ’è¡Œæ¦œé 
url = "https://www.books.com.tw/web/sys_tdrntb/books/"
res = session.get(url)
soup = BeautifulSoup(res.text, "html.parser")
books = soup.select("li.item")

# é–‹å§‹çˆ¬èŸ²
seen_links = set()
idx = 1
error_count = 0

import csv

# å»ºç«‹ä¸€å€‹æ¸…å–®ä¾†å­˜æ¯æœ¬æ›¸çš„è³‡æ–™
book_data = []

for book in books[23:73]:
    title_tag = book.select_one("h4 > a")
    if not title_tag:
        continue

    original_link = title_tag["href"]
    book_id = original_link.split("/products/")[-1].split("?")[0]
    link = f"https://www.books.com.tw/products/{book_id}/{idx}"

    if link in seen_links:
        continue
    seen_links.add(link)

    title = title_tag.text.strip()
    author_tag = book.select_one("ul.msg li:nth-of-type(1) a")
    author = author_tag.text.strip() if author_tag else "æœªçŸ¥ä½œè€…"

    price_tag = book.select_one("ul.msg li.price_a")
    price = "æœªçŸ¥åƒ¹æ ¼"
    if price_tag:
        price_text = price_tag.get_text(strip=True)
        if "å…ƒ" in price_text:
            price = price_text.split("å…ƒ")[0].split("æŠ˜")[-1] + "å…ƒ"

    category = get_category(link)

    if category not in category_count:
        category_count[category] = 1
    else:
        category_count[category] += 1

    if "ç•°å¸¸" in category or "å¤±æ•—" in category:
        error_count += 1
    else:
        error_count = 0

    if error_count >= 1:
        print("âš ï¸ é€£çºŒå‡ºéŒ¯è¶…é 5 æ¬¡ï¼Œæš«åœ 60 ç§’...")
        time.sleep(60)
        error_count = 0
        category = get_category(link)

    print(f"{idx}. æ›¸å: {title}")
    print(f"    é€£çµ: {link}")
    print(f"    ä½œè€…: {author}")
    print(f"    åƒ¹æ ¼: {price}")
    print(f"    åˆ†é¡: {category}")
    idx += 1

    # æŠŠé€™ç­†è³‡æ–™åŠ å…¥ list
    book_data.append([title, author, price, category, link])

# å¯«å…¥ CSV æª”æ¡ˆ
with open("static.csv", "w", newline="", encoding="utf-8-sig") as f:
    writer = csv.writer(f)
    writer.writerow(["æ›¸å", "ä½œè€…", "åƒ¹æ ¼", "åˆ†é¡", "é€£çµ"])
    writer.writerows(book_data)


print("\nğŸ“Š åˆ†é¡çµ±è¨ˆçµæœï¼ˆä¾å‡ºç¾æ¬¡æ•¸æ’åºï¼‰ï¼š")
for cat, count in sorted(category_count.items(), key=lambda x: x[1], reverse=True):
    print(f"åˆ†é¡ã€Œ{cat}ã€å‡ºç¾æ¬¡æ•¸ï¼š{count}")

import pandas as pd
import csv
from datetime import datetime
import pytz

# è®€å– static.csvï¼ˆä½ çš„çˆ¬èŸ²è¼¸å‡ºï¼‰
df = pd.read_csv("static.csv")

# çµ±è¨ˆåˆ†é¡å‡ºç¾æ¬¡æ•¸
category_count = df["åˆ†é¡"].value_counts().sort_values(ascending=False)


# è¨­å®šæ™‚å€ç‚ºå°ç£
tz = pytz.timezone("Asia/Taipei")
# å–å¾—ç•¶å‰æ™‚é–“
now = datetime.now(tz).strftime("%Y-%m-%d %H:%M:%S")

# çµ„åˆä¸€åˆ—ï¼šæ™‚é–“ + Top åˆ†é¡(æ¬¡æ•¸)
row = [now] + [f"{cat}({count})" for cat, count in category_count.items()]

# æª¢æŸ¥æ¬„ä½é•·åº¦æ˜¯å¦è¦æ›´æ–°ï¼ˆé¿å…æ¬„ä½ä¸è¶³ï¼‰
csv_file = "category_log.csv"
try:
    with open(csv_file, newline='', encoding='utf-8-sig') as f:
        reader = csv.reader(f)
        header = next(reader)
except FileNotFoundError:
    header = ["æ™‚é–“"]
if len(row) > len(header):
    header = ["æ™‚é–“"] + [f"Top{i}" for i in range(1, len(row))]

# å¯«å…¥è³‡æ–™ï¼ˆé™„åŠ ï¼‰
with open(csv_file, "a", newline="", encoding="utf-8-sig") as f:
    writer = csv.writer(f)
    # å¦‚æœæ˜¯ç©ºæª”æ¡ˆï¼Œè£œå¯«æ¬„ä½
    if f.tell() == 0:
        writer.writerow(header)
    writer.writerow(row)

print("âœ… å·²å¾ static.csv çµ±è¨ˆåˆ†é¡ä¸¦å¯«å…¥ category_log.csv")

import csv

csv_file = "category_log.csv"

try:
    with open(csv_file, newline='', encoding='utf-8-sig') as f:
        reader = csv.reader(f)
        rows = list(reader)

        if not rows:
            print("âŒ æª”æ¡ˆæ˜¯ç©ºçš„")
        else:
            print("ğŸ“‹ category_log.csv å…§å®¹å¦‚ä¸‹ï¼š\n")
            for row in rows:
                print(" ï½œ ".join(row))

except FileNotFoundError:
    print("âŒ æ‰¾ä¸åˆ°æª”æ¡ˆ category_log.csv")
except Exception as e:
    print("âŒ ç™¼ç”ŸéŒ¯èª¤ï¼š", e)